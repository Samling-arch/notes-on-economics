好的，我们继续深入学习，这次是SQL实战的下半部分，包括更复杂的综合题、面试真题，并初步探索指标体系。依然是为你量身定制的Obsidian Markdown格式笔记。

# 1 【数据分析】【金九银十】第三集（下）：SQL实例之综合题&面试真题，附带指标体系初探！卷起来！

大家好，我是渭河。这篇笔记紧接上一部分的SQL实战，我们将挑战更具综合性的题目和一些真实的面试题，并在最后一起初步了解什么是“指标体系”。

## 1.1 本期视频核心内容回顾

**通俗概括：** 上半集我们热了身，这下半集要上“硬菜”了！我们会做更难的SQL题，看看面试官可能会怎么考你，最后再聊聊数据分析师常说的“指标”到底是个啥玩意儿。

*   **延续实战：** 继续使用之前的模拟数据库表（学生表、课程表、教师表、成绩表、上课流水表）进行SQL编写。
*   **难度升级：**
    *   **综合性题目：** 需要组合运用多种SQL知识点，逻辑更复杂。
    *   **面试真题模拟：** 引入一些在数据分析师面试中常见的SQL考核题目，让你感受真实面试的难度和题型。
*   **指标体系初探：**
    *   **什么是指标？** 解释指标在公司业务中的作用。
    *   **指标体系的来源：** 探讨指标是如何产生的，它们与业务需求的关系。
    *   **从取数到指标：** 如何从日常的SQL取数工作，逐步理解和构建指标体系，提升自己的分析能力。

## 1.2 数据库表结构 (再次强调，与上篇一致)

**通俗概括：** 动手前，再看一眼我们的“工具箱”——有哪些表，表里有哪些信息。

1.  **`Student` (学生表)**
    *   `SID` (VARCHAR or INT): 学生编号
    *   `Sname` (VARCHAR): 学生姓名
    *   `Ssex` (VARCHAR): 学生性别 ('男', '女')

2.  **`Course` (课程表)**
    *   `CID` (VARCHAR or INT): 课程编号
    *   `Cname` (VARCHAR): 课程名称
    *   `TID` (VARCHAR or INT): 教师编号
    *   `Ctype` (VARCHAR): 课程类型 (例如: '文科', '理科')

3.  **`Teacher` (教师表)**
    *   `TID` (VARCHAR or INT): 教师编号
    *   `Tname` (VARCHAR): 教师姓名

4.  **`SC` (Score / 成绩表)**
    *   `SID` (VARCHAR or INT): 学生编号
    *   `CID` (VARCHAR or INT): 课程编号
    *   `Score` (DECIMAL or INT): 成绩

5.  **`Class_Log` (上课流水表 - 含时序)**
    *   `LogID` (INT): 日志ID
    *   `SID` (VARCHAR or INT): 学生编号
    *   `CID` (VARCHAR or INT): 课程编号
    *   `Class_Date` (DATE): 上课日期
    *   `Start_Time` (TIMESTAMP or VARCHAR): 上课开始时间
    *   `End_Time` (TIMESTAMP or VARCHAR): 上课结束时间
    *   `DT` (VARCHAR): 数据分区字段 (例如: '20231027')

---

## 1.3 SQL 实战题目与解析 (续)

**通俗概括：** 继续解题，这次的题目会更考验我们的综合运用能力和逻辑思维。

(注意：视频中第一部分题目与上篇笔记内容有重叠，这里我们直接从新的、更综合的题目或面试题开始，或者对已有题目进行更深入的探讨。)

我们已经回顾了之前的问题1到问题6。现在假设我们进入面试真题或更复杂的综合题环节。

---

### 1.3.1 面试真题/综合题示例1：查询连续登录N天的用户

**通俗概括：** 找出那些在某个时间段内，连续登录了至少N天的用户。例如，找出本月连续登录超过3天的用户。

**场景假设：**
我们有一张用户登录日志表 `User_Login_Log`：
*   `UserID` (INT): 用户ID
*   `Login_Date` (DATE): 登录日期
*   `DT` (VARCHAR): 数据分区

**需求：** 查询在指定月份（例如 '2023-10'），连续登录天数达到或超过 $3$ 天的用户ID及其最大连续登录天数。

**思路分析 (这是一个经典且稍复杂的面试题)：**
这个问题核心在于如何判断“连续”。有几种常见思路：
1.  **`LAG()` 窗口函数与分组求和/计数：**
    *   用 `LAG()` 获取上一条登录日期。
    *   计算当前登录日期与上一条登录日期的差值。如果差值为 $1$ 天，则认为是连续的。
    *   给连续的段打上标记，然后对标记进行分组，计算每个连续段的长度。
2.  **`ROW_NUMBER()` 差值法：**
    *   对每个用户的登录记录按日期排序，生成一个行号 `rn1`。
    *   对每个用户的登录记录按日期排序，并将日期转换为自某个基准点以来的天数（或直接用日期减去一个固定偏移的行号），生成另一个序列 `rn2` (比如 `DATEDIFF(Login_Date, '1970-01-01') - ROW_NUMBER() OVER (PARTITION BY UserID ORDER BY Login_Date)` )。
    *   如果日期是连续的，那么 `Login_Date` (转换成天数后) 减去 `rn1` 的差值应该是一个常数。这个常数可以用来标识一个连续的登录段。
    *   然后按 `UserID` 和这个差值分组，计算每个组内的天数（即连续天数）。

**解法：使用 `LAG()` 和 分组计数 (思路1的简化版)**

```markdown
$$
WITH Login_With_Lag AS (
    -- 步骤1: 为每个用户的每次登录记录，获取其上一次登录日期
    SELECT
        UserID,
        Login_Date,
        LAG(Login_Date, 1, NULL) OVER (PARTITION BY UserID ORDER BY Login_Date) AS Prev_Login_Date
    FROM
        User_Login_Log
    WHERE
        SUBSTRING(CAST(Login_Date AS VARCHAR), 1, 7) = '2023-10' -- 筛选指定月份
        -- 或者在Hive中: WHERE DT LIKE '202310%' AND SUBSTRING(Login_Date, 1, 7) = '2023-10'
),
Login_With_Group_Flag AS (
    -- 步骤2: 标记连续登录段的开始
    -- 如果当前登录日期与上一次登录日期不是连续的（或没有上一次登录），则标记为新的连续段开始 (Is_New_Segment = 1)
    SELECT
        UserID,
        Login_Date,
        CASE
            WHEN Prev_Login_Date IS NULL OR DATEDIFF(Login_Date, Prev_Login_Date) != 1 THEN 1
            ELSE 0
        END AS Is_New_Segment
    FROM
        Login_With_Lag
),
Login_With_Segment_ID AS (
    -- 步骤3: 为每个连续登录段分配一个唯一的ID
    -- 通过对 Is_New_Segment 进行累加和来实现
    SELECT
        UserID,
        Login_Date,
        SUM(Is_New_Segment) OVER (PARTITION BY UserID ORDER BY Login_Date ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS Segment_ID
    FROM
        Login_With_Group_Flag
),
Consecutive_Login_Counts AS (
    -- 步骤4: 计算每个连续登录段的长度（即连续登录天数）
    SELECT
        UserID,
        Segment_ID,
        COUNT(*) AS Consecutive_Days,
        MIN(Login_Date) AS Segment_Start_Date, -- 该连续段的开始日期
        MAX(Login_Date) AS Segment_End_Date   -- 该连续段的结束日期
    FROM
        Login_With_Segment_ID
    GROUP BY
        UserID, Segment_ID
)
-- 步骤5: 筛选出连续登录天数 >= 3 的用户，并找出每个用户在本月最大的连续登录天数
SELECT
    UserID,
    MAX(Consecutive_Days) AS Max_Consecutive_Login_Days_This_Month
FROM
    Consecutive_Login_Counts
WHERE
    Consecutive_Days >= 3
GROUP BY
    UserID;
$$
```

*   **代码解释 (逐步拆解，使用了`WITH`子句定义公共表表达式CTE)：**
    *   **`WITH Login_With_Lag AS (...)` (CTE 1):**
        *   `LAG(Login_Date, 1, NULL) OVER (PARTITION BY UserID ORDER BY Login_Date) AS Prev_Login_Date`:
            *   `LAG(Login_Date, 1, NULL)`: 获取 `Login_Date` 列，往前推 $1$ 行的值。如果前一行不存在（比如用户的第一条登录记录），则返回 `NULL` (第三个参数是默认值)。
            *   `PARTITION BY UserID`: 在每个用户内部独立计算 `LAG`。
            *   `ORDER BY Login_Date`: 按登录日期排序，这样 `LAG` 才能正确取到“上一次”登录。
        *   结果：每条登录记录都会附带上该用户上一次的登录日期。
    *   **`Login_With_Group_Flag AS (...)` (CTE 2):**
        *   `CASE WHEN Prev_Login_Date IS NULL OR DATEDIFF(Login_Date, Prev_Login_Date) != 1 THEN 1 ELSE 0 END AS Is_New_Segment`:
            *   `DATEDIFF(date1, date2)`: 计算 `date1` 和 `date2` 之间的天数差。如果 `Login_Date` 和 `Prev_Login_Date` 相差 $1$ 天，说明是连续的。
            *   如果上一次登录日期是 `NULL`（首次登录），或者与上一次登录不连续，则标记 `Is_New_Segment` 为 $1$ (表示新连续段的开始)，否则为 $0$。
    *   **`Login_With_Segment_ID AS (...)` (CTE 3):**
        *   `SUM(Is_New_Segment) OVER (PARTITION BY UserID ORDER BY Login_Date ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS Segment_ID`:
            *   这是一个巧妙的技巧，用累加和来为每个连续段生成一个ID。
            *   `ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW`: 定义了窗口框架，表示从分区的第一行到当前行。
            *   当遇到 `Is_New_Segment = 1` 时，累加和会增加，从而为新的连续段赋予一个新的 `Segment_ID`。同一个连续段内的 `Is_New_Segment` 都是 $0$ (除了第一条)，所以它们的 `Segment_ID` 会保持不变。
    *   **`Consecutive_Login_Counts AS (...)` (CTE 4):**
        *   `GROUP BY UserID, Segment_ID`: 按用户ID和我们刚生成的连续段ID分组。
        *   `COUNT(*) AS Consecutive_Days`: 计算每个段内有多少条记录，即连续登录了多少天。
    *   **最终 `SELECT` 语句:**
        *   `FROM Consecutive_Login_Counts WHERE Consecutive_Days >= 3`: 从计算出的连续登录段中，筛选出那些连续天数大于等于 $3$ 的段。
        *   `SELECT UserID, MAX(Consecutive_Days) AS Max_Consecutive_Login_Days_This_Month GROUP BY UserID`: 对于每个用户，找出他所有满足条件的连续登录段中，最长的那一次是多少天。

*   **来源与重要性：**
    *   这类问题在用户行为分析中非常常见，比如分析用户粘性、活跃度等。
    *   考察对窗口函数 (`LAG`, `SUM() OVER()`)、CTE (公共表表达式 `WITH`)、日期函数 (`DATEDIFF`) 以及逻辑构建能力的综合运用。
    *   面试官通过这类题目能快速判断候选人的SQL熟练度和解决复杂问题的能力。

---

### 1.3.2 面试真题/综合题示例2：计算用户次日留存率

**通俗概括：** 今天来了一批新用户，看看他们之中有多少人明天还会再来。这个比例就是次日留存率。

**场景假设：**
我们有一张用户行为日志表 `User_Activity_Log`:
*   `UserID` (INT): 用户ID
*   `Event_Date` (DATE): 事件发生日期 (可以是用户首次活跃日期，或每日活跃日期)
*   `Is_New_User` (BOOLEAN or INT): 标记是否为新用户 (例如，当天首次在本平台活跃)

**需求：** 计算某一天 (例如 '2023-10-10') 的新用户，在次日 ('2023-10-11') 的留存率。
留存率 = (在 '2023-10-10' 是新用户 且 在 '2023-10-11' 仍然活跃的用户数) / (在 '2023-10-10' 的新用户总数)

**思路分析：**
1.  找出指定日期 ('2023-10-10') 的所有新用户。
2.  对于这些新用户，检查他们是否在次日 ('2023-10-11') 也有活动记录。
3.  分别计算步骤1的总人数和步骤2中次日仍活跃的人数。
4.  两者相除得到留存率。

**解法：使用 `LEFT JOIN` 或 `EXISTS`**

```markdown
$$
WITH New_Users_On_Day1 AS (
    -- 步骤1: 找出 '2023-10-10' 的新用户
    SELECT DISTINCT UserID -- DISTINCT确保每个新用户只算一次
    FROM User_Activity_Log
    WHERE Event_Date = DATE('2023-10-10')
      AND Is_New_User = TRUE -- 或者 Is_New_User = 1
),
Retained_Users_On_Day2 AS (
    -- 步骤2: 找出这些新用户中，在 '2023-10-11' 仍然活跃的
    SELECT DISTINCT U1.UserID
    FROM New_Users_On_Day1 U1
    JOIN User_Activity_Log UAL_Day2
      ON U1.UserID = UAL_Day2.UserID
     AND UAL_Day2.Event_Date = DATE('2023-10-11')
)
-- 步骤3 & 4: 计算留存率
SELECT
    (SELECT COUNT(*) FROM Retained_Users_On_Day2) * 1.0 / (SELECT COUNT(*) FROM New_Users_On_Day1) AS Next_Day_Retention_Rate;
$$
```

*   **代码解释：**
    *   **`New_Users_On_Day1` (CTE 1):**
        *   选出 `Event_Date` 为 '2023-10-10' 且 `Is_New_User` 为真的用户ID。
        *   `DISTINCT UserID`: 确保如果一个新用户当天有多条活动记录，也只被计数一次。
    *   **`Retained_Users_On_Day2` (CTE 2):**
        *   `FROM New_Users_On_Day1 U1`: 从第一天的新用户列表开始。
        *   `JOIN User_Activity_Log UAL_Day2 ON U1.UserID = UAL_Day2.UserID AND UAL_Day2.Event_Date = DATE('2023-10-11')`:
            *   将第一天的新用户 (`U1`) 与用户活动日志表 (`UAL_Day2`) 进行连接。
            *   连接条件是 `UserID` 相同，并且 `UAL_Day2` 中的 `Event_Date` 是次日 ('2023-10-11')。
            *   `INNER JOIN` 的效果是只保留那些在次日也有活动的用户。
        *   `DISTINCT U1.UserID`: 确保如果次日有多次活动，该留存用户也只被计数一次。
    *   **最终 `SELECT` 语句:**
        *   `(SELECT COUNT(*) FROM Retained_Users_On_Day2)`: 子查询，计算次日仍然活跃的新用户数量。
        *   `(SELECT COUNT(*) FROM New_Users_On_Day1)`: 子查询，计算第一天的新用户总数。
        *   `* 1.0 /`: 将分子乘以 `1.0` 是为了确保进行浮点数除法，得到小数形式的留存率，否则整数除法可能会得到 $0$。
        *   `AS Next_Day_Retention_Rate`: 给结果命名。

*   **另一种实现留存的常见方式 (使用 `LEFT JOIN` 和 `COUNT(DISTINCT CASE WHEN ...)`):**
    ```markdown
    $$
    SELECT
        COUNT(DISTINCT
            CASE
                WHEN UAL_Day2.UserID IS NOT NULL THEN UAL_Day1.UserID
                ELSE NULL
            END
        ) * 1.0 / COUNT(DISTINCT UAL_Day1.UserID) AS Next_Day_Retention_Rate
    FROM
        (SELECT DISTINCT UserID, Event_Date FROM User_Activity_Log WHERE Event_Date = DATE('2023-10-10') AND Is_New_User = TRUE) AS UAL_Day1
    LEFT JOIN
        (SELECT DISTINCT UserID, Event_Date FROM User_Activity_Log WHERE Event_Date = DATE('2023-10-11')) AS UAL_Day2
      ON UAL_Day1.UserID = UAL_Day2.UserID;
    $$
    ```
    *   这里，`LEFT JOIN` 会保留所有第一天的新用户。如果该用户在第二天也活跃，`UAL_Day2.UserID` 就不会是 `NULL`，我们就在 `CASE` 语句中计数这个 `UAL_Day1.UserID`。

*   **来源与重要性：**
    *   留存分析是衡量产品健康度、用户粘性的核心指标之一。
    *   面试中常考，因为它结合了日期处理、用户识别、条件计数和比率计算。

---

## 1.4 指标体系初探

**通俗概括：** SQL帮我们从数据海洋里捞鱼（数据），而“指标”就是告诉我们这些鱼有多大、多重、什么品种，帮我们判断渔获好不好。“指标体系”就是一套衡量标准，系统地告诉我们业务的方方面面怎么样了。

*   **什么是指标 (Metric / KPI - Key Performance Indicator)？**
    *   **定义：** 指标是用于衡量业务表现、过程效率、产品健康度等特定方面的 **可量化** 的数值。
    *   **例子：**
        *   网站：日活跃用户数 (DAU)、用户平均停留时长、转化率 (如下单用户数/访问用户数)。
        *   电商：GMV (Gross Merchandise Volume, 总成交额)、客单价、复购率。
        *   内容平台：内容发布数、用户互动数 (点赞、评论、分享)、用户阅读完成率。
    *   **作用：**
        *   **监控 (Monitoring):** 实时了解业务状态，发现异常。
        *   **评估 (Evaluation):** 判断某个策略、功能、活动的效果。
        *   **决策 (Decision Making):** 为业务决策提供数据支持。
        *   **目标设定 (Goal Setting):** 为团队或产品设定可衡量的目标。

*   **指标体系 (Metric System / Framework) 是什么？**
    *   **定义：** 不是单个孤立的指标，而是一组 **相互关联、系统化、结构化** 的指标集合，它们共同反映了业务的整体状况和关键环节。
    *   **特征：**
        *   **层次性：** 可能包含核心战略指标（如公司利润）、业务过程指标（如用户转化漏斗各环节转化率）、基础监控指标（如服务器错误率）。
        *   **关联性：** 指标之间可能存在因果关系或相关性（如提高用户活跃度可能带来更高的付费转化）。
        *   **全面性：** 尽量覆盖业务的关键方面，避免片面。
        *   **指导性：** 能够指导业务方向和资源分配。
    *   **例子 (一个简化的电商指标体系可能包括)：**
        *   **流量层：** 访问用户数 (UV)、页面浏览量 (PV)、新用户数、流量来源分布。
        *   **转化层：** 注册转化率、商品详情页到购物车的转化率、购物车到下单的转化率、支付成功率。
        *   **营收层：** GMV、订单数、客单价、利润率。
        *   **用户层：** 用户留存率、用户生命周期价值 (LTV)、用户满意度。

*   **指标体系的来源与构建思路？**
    1.  **理解业务目标：** 公司的战略目标是什么？当前业务阶段的核心关注点是什么？ (例如，是追求用户增长，还是提升盈利能力？)
    2.  **拆解业务流程：** 将复杂的业务流程分解为关键环节和用户行为路径 (例如，用户从看到广告 -> 点击 -> 访问落地页 -> 注册 -> 首次购买 -> 复购 的完整路径)。
    3.  **识别关键节点：** 在业务流程中，哪些节点的效率和表现对整体目标影响最大？
    4.  **定义衡量指标：** 为每个关键节点或关键行为设定可量化的衡量指标。
        *   **AARRR模型 (海盗模型)：** 常用于用户增长分析，包括 Acquisition (获取)、Activation (激活)、Retention (留存)、Revenue (收入)、Referral (推荐)。可以围绕这些环节设计指标。
        *   **OSM模型 (Object-Strategy-Measurement)：** 目标-策略-衡量。
    5.  **数据埋点与收集：** 确保有相应的数据来源来计算这些指标 (这通常需要产品、开发和数据团队协作进行数据埋点设计)。
    6.  **指标校验与迭代：** 指标不是一成不变的，需要根据业务发展和数据反馈进行调整和优化。某些指标可能不再适用，需要引入新的指标。

*   **从SQL取数到理解指标体系的进阶：**
    *   **理解“为什么取这个数”：** 当业务方给你一个取数需求时，不仅仅是机械地写SQL，更要思考：
        *   这个数据是用来衡量什么的？(它对应哪个指标？)
        *   这个指标在业务中处于什么位置？(它是核心指标还是过程指标？)
        *   这个指标的变化会影响什么？(它与其他指标有什么关联？)
    *   **主动思考与建议：** 基于对数据的理解，能否发现一些业务方没有直接提出的潜在问题或机会？能否建议更合理的指标或分析维度？
    *   **参与指标定义：** 随着经验的积累，可以逐步参与到新指标的定义和现有指标体系的优化中。
    *   **数据可视化与解读：** 将计算出来的指标通过图表等方式清晰地呈现，并能解读其背后的业务含义和趋势。

*   **视频中的例子 (上课时长)：**
    *   “每个学生的上课总时长”、“某一科的上课总时长”这些都是基础的 **描述性统计量**。
    *   如果我们将这些数据用于评估：
        *   学生的学习投入度 (指标)。
        *   不同课程的受欢迎程度或学时安排的合理性 (通过对比不同课程的总时长或平均时长)。
        *   不同性别学生在不同类型课程上的学时差异 (探索性分析)。
    *   如果学校设定了“每个学生每月专业课学习时长不低于 $X$ 小时”作为目标，那么“学生专业课月度学习时长”就是一个 **KPI**。

## 1.5 总结

**通俗概括：** SQL是数据分析师的“剑”，指标体系是“剑谱”。光学了招式还不够，还要理解为什么这么出招，以及如何组合招式来克敌制胜（解决业务问题）。

*   **SQL是基础：** 熟练掌握SQL是进行数据分析的前提。
*   **指标是方向：** 理解指标体系能让你明白分析工作的目的和价值。
*   **持续学习：** 数据分析是一个不断学习和实践的过程，从技术到业务理解，都需要持续精进。
*   **卷起来！：** 视频标题的“卷起来”是句玩笑话，但也反映了这个行业需要不断学习新知识、提升技能的态势。

---

希望这份下半集的笔记能帮助你巩固SQL实战技能，并对指标体系有一个初步的认识。数据分析的道路，从写好每一条SQL开始，逐步走向更广阔的业务洞察天地！