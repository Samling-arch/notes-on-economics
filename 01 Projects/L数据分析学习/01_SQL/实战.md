# 1 了解知识：手撕大厂SQL真题解析 (基于B站视频 BV1je4y1b7YU)

## 1.1 零、开篇明义：为什么要学好SQL？

*   **一句话概括**：学好SQL不仅面试要考，更是工作中提高效率、早点下班的利器！
*   **面试需求**：面试时，SQL是很多技术岗位的必考项，尤其数据分析、后端开发等。
*   **工作提效**：工作中，大量数据处理和分析都依赖SQL。写出高效的SQL，能让你从繁杂的数据任务中解脱出来，早点完成工作，告别不必要的加班。
*   **内容预告**：这个系列会讲解几个核心SQL专题，包括：
    *   行转列
    *   连续登录
    *   N日留存率
    *   分组内TopN
    *   窗口函数
    *   带条件的聚合统计
*   **目标**：掌握这些专题的“公式化”解法，面试遇到类似问题就能信手拈来。

---

## 1.2 一、SQL执行顺序回顾

*   **一句话概括**：我们写的SQL语句，看着是一整块，但数据库执行它的时候，其实是按一套固定的“先后顺序”来处理里面的关键字的，就像做菜有步骤一样。
*   **重要性**：理解SQL的执行顺序是写出正确且高效SQL的基础，尤其是复杂查询。把它变成你的“潜意识”，能避免很多逻辑错误。
*   **场景1：包含 `GROUP BY` 的查询**
    *   **示例SQL结构**：
        ```sql
        SELECT ... 
        FROM table1
        JOIN table2 ON ...
        WHERE ...
        GROUP BY ...
        HAVING ...
        ORDER BY ...
        LIMIT ...;
        ```
    *   **执行顺序详解**：
        1.  **`FROM`**： `$1$`号选手，指定从哪个或哪些表开始拿数据。这是数据源的起点。
        2.  **`ON` / `JOIN`**： `$2$`号选手，如果有多表连接 (`JOIN`)，`ON` 子句会根据连接条件筛选匹配的行，形成一个初步的、可能很大的中间结果集。`JOIN` 和 `ON` 几乎是同时作用的。
        3.  **`WHERE`**： `$3$`号选手，对上一步产生的中间结果集进行行级过滤，不符合`WHERE`条件的行会被丢弃。
        4.  **`GROUP BY`**： `$4$`号选手，根据指定的列对`WHERE`过滤后的结果进行分组。相同的值会被分到同一组。
        5.  **聚合函数计算 (如 `COUNT()`, `SUM()`, `AVG()` 等)**： `$5$`号选手，`GROUP BY` 之后，`SELECT` 子句中的聚合函数会作用于每个分组，计算出聚合结果。
        6.  **`HAVING`**： `$6$`号选手，对`GROUP BY`分组并进行聚合函数计算后的结果进行组级过滤。注意，`HAVING` 是对分组后的结果进行筛选，`WHERE` 是在分组前。
        7.  **`SELECT`**： `$7$`号选手，选择最终要显示的列。此时，非聚合列必须是`GROUP BY`子句中的列。
        8.  **`DISTINCT`** (如果存在)： `$8$`号选手，对`SELECT`出来的结果进行去重。
        9.  **`ORDER BY`**： `$9$`号选手，对最终的结果集进行排序。
        10. **`LIMIT` / `OFFSET`**： `$10$`号选手，对排序后的结果集进行分页或限制返回的行数。

*   **场景2：不包含 `GROUP BY` (但可能包含 `DISTINCT`) 的查询**
    *   **示例SQL结构**：
        ```sql
        SELECT DISTINCT ...
        FROM table1
        JOIN table2 ON ...
        WHERE ...
        ORDER BY ...
        LIMIT ...;
        ```
    *   **执行顺序详解**：
        1.  **`FROM`**： `$1$`号选手。
        2.  **`ON` / `JOIN`**： `$2$`号选手。
        3.  **`WHERE`**： `$3$`号选手。
        4.  **`SELECT`**： `$4$`号选手。
        5.  **`DISTINCT`**： `$5$`号选手，在`SELECT`之后对结果去重。
        6.  **`ORDER BY`**： `$6$`号选手。
        7.  **`LIMIT` / `OFFSET`**： `$7$`号选手。

*   **核心记忆点**：
    *   `FROM` 是最早的，确定数据来源。
    *   `WHERE` 在 `GROUP BY` 之前，`HAVING` 在 `GROUP BY` 之后。
    *   `SELECT` 的实际执行（选择列和计算表达式）其实比较靠后。
    *   `DISTINCT` 在 `SELECT` 之后，`ORDER BY` 之前。
    *   `ORDER BY` 和 `LIMIT` 是最后阶段处理的。

---

## 1.3 二、专题一：行转列

*   **一句话概括**：就是把原来竖着几行显示的数据，变成横着几列显示，信息本身没变，只是展示的“队形”变了，通常是为了更方便地对比和查看。
*   **为什么常见**：这种转换在报表展示、数据对比分析中非常实用。
*   **核心公式**：`GROUP BY` + `聚合函数(IF(条件, 真值, 假值))` 或者 `聚合函数(CASE WHEN 条件 THEN 真值 ELSE 假值 END)`
    *   **`GROUP BY` 的作用**：行转列后，通常行的数量会减少（比如原来按月份有多行，现在按年份只有一行），所以需要一个维度进行分组，这个维度就是转换后保持不变的列（如年份）。
    *   **`聚合函数(IF/CASE WHEN)` 的作用**：
        *   `IF(条件, 真值, 假值)` (在MySQL, Hive中常用) 或 `CASE WHEN 条件 THEN 真值 ELSE 假值 END` (更通用，所有SQL数据库都支持) 用于判断。
        *   对于每一行数据，根据它是否满足新列的条件，来决定这一行对新列的贡献值。
        *   `聚合函数`（通常是 `SUM`, `COUNT`, `MAX`, `MIN` 等）将这些贡献值在`GROUP BY`的分组内进行汇总，形成新列的值。

### 1.3.1 例子1：华泰证券面试题

*   **原始表 (假设表名叫 `sales_data`)**：
    | year | month | amount |
    | :--- | :---- | :----- |
    | 1991 | 1     | 1.1    |
    | 1991 | 2     | 1.2    |
    | 1991 | 3     | 1.3    |
    | 1991 | 4     | 1.4    |
    | 1992 | 1     | 2.1    |
    | 1992 | 2     | 2.2    |
    | ...  | ...   | ...    |
*   **目标表**：
    | year | m1  | m2  | m3  | m4  |
    | :--- | :-- | :-- | :-- | :-- |
    | 1991 | 1.1 | 1.2 | 1.3 | 1.4 |
    | 1992 | 2.1 | 2.2 | ... | ... |
*   **使用的数据库环境**：老师演示用了 `Hive` (大数据环境中的SQL)，但这个逻辑在 `MySQL`, `PostgreSQL`, `SQL Server` 等数据库中是通用的，只是个别函数名可能略有差异（比如 `IF` 在 SQL Server 中可能用 `IIF` 或者 `CASE WHEN`）。
*   **开发工具**：`DataGrip`

*   **SQL代码实现与解析**：

    *   **步骤1：创建表和插入数据 (Hive SQL 示例)**
        ```sql
        -- 老师可能先 USE 了一个数据库，比如 USE interview_db;
        -- 创建表
        CREATE TABLE IF NOT EXISTS sales_data (
            year INT,
            month INT,
            amount DECIMAL(10,2) -- DECIMAL(总位数, 小数位数)
        );

        -- 插入数据 (实际工作中可能是从文件加载)
        INSERT INTO sales_data VALUES
        (1991, 1, 1.1),
        (1991, 2, 1.2),
        (1991, 3, 1.3),
        (1991, 4, 1.4),
        (1992, 1, 2.1),
        (1992, 2, 2.2); 
        -- 老师演示时表名可能叫 table2，这里为了清晰改为 sales_data
        ```

    *   **步骤2：行转列查询 (一步到位版)**
        ```sql
        SELECT
            year, -- 分组的维度，转换后依然是列
            -- 下面是转换出来的新列
            -- 对于1月份的销售额 (m1)
            SUM(IF(month = 1, amount, 0)) AS m1, 
            -- 解释: 如果当前行的月份是1月，就取它的amount值；否则取0。
            -- 然后SUM会把同一年份下所有符合month=1的amount加起来 (其他月份贡献的是0，不影响结果)。

            -- 对于2月份的销售额 (m2)
            SUM(IF(month = 2, amount, 0)) AS m2,

            -- 对于3月份的销售额 (m3)
            SUM(IF(month = 3, amount, 0)) AS m3,

            -- 对于4月份的销售额 (m4)
            SUM(IF(month = 4, amount, 0)) AS m4
            -- 如果有更多月份，以此类推
        FROM
            sales_data -- 从原始数据表取数
        GROUP BY
            year; -- 按年份分组，因为我们希望最终结果是每年一行
        ```
        **通用写法 (使用 `CASE WHEN`)**：
        ```sql
        SELECT
            year,
            SUM(CASE WHEN month = 1 THEN amount ELSE 0 END) AS m1,
            SUM(CASE WHEN month = 2 THEN amount ELSE 0 END) AS m2,
            SUM(CASE WHEN month = 3 THEN amount ELSE 0 END) AS m3,
            SUM(CASE WHEN month = 4 THEN amount ELSE 0 END) AS m4
        FROM
            sales_data
        GROUP BY
            year;
        ```
        **#细节追问#：为什么 `IF` 语句的 `ELSE` 部分是 `$0$`？**
        因为我们用的是 `SUM` 聚合函数。对于特定年份（比如1991年）的 `m1` 列，我们只关心1月份的 `amount`。当 `month` 不是 `$1$` 时，我们给它一个 `$0$`，这样在求和时，这些非1月份的记录对 `m1` 的总和贡献为 `$0$`，不会影响1月份 `amount` 的累加。

    *   **步骤3：理解其背后逻辑 (拆解成两步思考，虽然实际写成一步)**
        虽然上面是一步写完的，但它的逻辑可以理解为两步：
        1.  **内部转换/打标签 (概念上的中间表)**：
            想象先生成一个中间表，把每个月的数据“映射”到对应的目标列上，其他列填0。
            ```sql
            -- 这不是实际执行的语句，而是帮助理解的思路
            SELECT
                year,
                month,
                amount,
                IF(month = 1, amount, 0) AS for_m1, -- 如果是1月，amount给for_m1，否则0
                IF(month = 2, amount, 0) AS for_m2, -- 如果是2月，amount给for_m2，否则0
                IF(month = 3, amount, 0) AS for_m3,
                IF(month = 4, amount, 0) AS for_m4
            FROM sales_data;
            ```
            这个概念上的结果会是：
            | year | month | amount | for_m1 | for_m2 | for_m3 | for_m4 |
            | :--- | :---- | :----- | :----- | :----- | :----- | :----- |
            | 1991 | 1     | 1.1    | 1.1    | 0      | 0      | 0      |
            | 1991 | 2     | 1.2    | 0      | 1.2    | 0      | 0      |
            | 1991 | 3     | 1.3    | 0      | 0      | 1.3    | 0      |
            | 1991 | 4     | 1.4    | 0      | 0      | 0      | 1.4    |
            | 1992 | 1     | 2.1    | 2.1    | 0      | 0      | 0      |
            | 1992 | 2     | 2.2    | 0      | 2.2    | 0      | 0      |

        2.  **外部聚合**：
            然后对这个概念上的中间表按 `year` 分组，并对 `for_m1`, `for_m2` 等列求和。
            ```sql
            -- 续上一步的思路
            SELECT
                year,
                SUM(for_m1) AS m1,
                SUM(for_m2) AS m2,
                SUM(for_m3) AS m3,
                SUM(for_m4) AS m4
            FROM ( -- 上面概念上的中间结果 -- ) AS temp_table
            GROUP BY year;
            ```
            你看，对于1991年，`SUM(for_m1)` 就是 `1.1 + 0 + 0 + 0 = 1.1`。 `SUM(for_m2)` 就是 `0 + 1.2 + 0 + 0 = 1.2`。
            这就是为什么一步到位的写法是有效的。

    **#细节追问#：`IF` 和 `CASE WHEN` 的选择？**
    *   `CASE WHEN condition THEN result ELSE default_result END` 是SQL标准语法，所有数据库都支持，功能更强大，可以写多个`WHEN...THEN...`分支。
    *   `IF(condition, result_if_true, result_if_false)` 是某些数据库（如MySQL, Hive）提供的简化版，只适用于二选一的简单判断。
    *   在只有两个互斥分支的情况下 (比如 `month = 1` 和 `month != 1`)，`IF(month = 1, amount, 0)` 等价于 `CASE WHEN month = 1 THEN amount ELSE 0 END`。
    *   老师提到的 `test.excution.mode=local` (应为 `hive.execution.engine=mr` 或 `tez` 或 `spark`， 或者 `set hive.exec.mode.local.auto=true;` 开启本地模式) 是Hive特有的性能优化参数，跟SQL逻辑本身关系不大，小白可以先忽略，知道这是为了让小查询在本地快点跑起来。

### 1.3.2 例子2：腾讯游戏面试题

*   **原始表 (假设表名叫 `game_results`)**：
    | date_str   | result |
    | :--------- | :----- |
    | 2015-05-09 | 胜     |
    | 2015-05-09 | 胜     |
    | 2015-05-09 | 负     |
    | 2015-05-09 | 负     |
    | 2015-05-10 | 胜     |
    | 2015-05-10 | 负     |
    | 2015-05-10 | 负     |
*   **目标表**：
    | date_str   | 胜利次数 | 失败次数 |
    | :--------- | :------- | :------- |
    | 2015-05-09 | 2        | 2        |
    | 2015-05-10 | 1        | 2        |
*   **SQL代码实现与解析**：

    *   **步骤1：创建表和插入数据 (Hive SQL 示例)**
        ```sql
        CREATE TABLE IF NOT EXISTS game_results (
            date_str STRING, -- 日期这里用字符串类型
            result STRING    -- 胜负结果用字符串
        );

        INSERT INTO game_results VALUES
        ('2015-05-09', '胜'),
        ('2015-05-09', '胜'),
        ('2015-05-09', '负'),
        ('2015-05-09', '负'),
        ('2015-05-10', '胜'),
        ('2015-05-10', '负'),
        ('2015-05-10', '负');
        -- 老师演示时表名可能叫 table1
        ```

    *   **步骤2：行转列查询**
        这里是统计次数，所以聚合函数用 `COUNT` 或者 `SUM` 都可以。
        **方法一：使用 `COUNT`**
        ```sql
        SELECT
            date_str, -- 分组维度
            COUNT(CASE WHEN result = '胜' THEN 1 ELSE NULL END) AS `胜利次数`, -- 注意中文列名用反引号
            COUNT(CASE WHEN result = '负' THEN 1 ELSE NULL END) AS `失败次数`
        FROM
            game_results
        GROUP BY
            date_str;
        ```
        **#细节追问#：为什么用 `COUNT` 时，`ELSE` 部分是 `NULL` 而不是 `$0$`？**
        *   `COUNT(expression)` 函数统计的是 `expression` **不为 `NULL`** 的值的个数。
        *   如果我们写 `CASE WHEN result = '胜' THEN 1 ELSE 0 END`，那么当 `result` 不是 '胜' 时，表达式结果是 `$0$`。`COUNT` 会把 `$0$` 也算作一个有效值，导致计数错误（它会把所有行都统计进去，因为 `$0$` 不是 `NULL`）。
        *   所以，当 `result` 不是 '胜' 时，我们给 `NULL`，这样 `COUNT` 就只统计 `result = '胜'` 的情况（因为那时表达式结果是 `$1$`，不是 `NULL`）。

        **方法二：使用 `SUM` (更常见也更推荐)**
        ```sql
        SELECT
            date_str,
            SUM(CASE WHEN result = '胜' THEN 1 ELSE 0 END) AS `胜利次数`,
            SUM(CASE WHEN result = '负' THEN 1 ELSE 0 END) AS `失败次数`
            -- 也可以用IF: SUM(IF(result = '胜', 1, 0))
        FROM
            game_results
        GROUP BY
            date_str;
        ```
        **#细节追问#：为什么用 `SUM` 时，`ELSE` 部分是 `$0$`？**
        *   `SUM(expression)` 计算的是 `expression` 的总和，它会自动忽略 `NULL` 值。
        *   当 `result = '胜'` 时，我们让表达式为 `$1$`；当 `result` 不是 '胜' 时，表达式为 `$0$`。
        *   `SUM` 把这些 `$1$` 和 `$0$` 加起来，结果正好就是 '胜' 的次数。比如某天3胜2负，对于“胜利次数”，`SUM` 计算的是 `1+1+1+0+0 = 3`。
        *   如果 `ELSE NULL`，`SUM` 会忽略 `NULL`，结果也是对的。`SUM(CASE WHEN result = '胜' THEN 1 ELSE NULL END)` 也能得到正确结果。但通常 `SUM` 配 `ELSE 0` 来计数更符合直觉。

    *   **步骤3：理解其背后逻辑 (以 `COUNT` 版本为例)**
        1.  **内部转换/打标签 (概念上的中间表)**：
            ```sql
            -- 思路演示
            SELECT
                date_str,
                result,
                CASE WHEN result = '胜' THEN 1 ELSE NULL END AS is_win,
                CASE WHEN result = '负' THEN 1 ELSE NULL END AS is_loss
            FROM game_results;
            ```
            结果：
            | date_str   | result | is_win | is_loss |
            | :--------- | :----- | :----- | :------ |
            | 2015-05-09 | 胜     | 1      | NULL    |
            | 2015-05-09 | 胜     | 1      | NULL    |
            | 2015-05-09 | 负     | NULL   | 1       |
            | 2015-05-09 | 负     | NULL   | 1       |
            | ...        | ...    | ...    | ...     |

        2.  **外部聚合**：
            对上面结果按 `date_str` 分组，然后 `COUNT(is_win)` 和 `COUNT(is_loss)`。
            对于 '2015-05-09'，`COUNT(is_win)` 统计 `is_win` 列中非 `NULL` 的个数，即 `$1, 1$` 这两个，所以是 `$2$`。
            `COUNT(is_loss)` 统计 `is_loss` 列中非 `NULL` 的个数，即 `$1, 1$` 这两个，所以是 `$2$`。

### 1.3.3 行转列小结

*   **核心**：`GROUP BY` + `聚合(条件判断)`
*   **聚合函数选择**：
    *   如果是求和、求平均等数值运算，通常用 `SUM()`, `AVG()` 等，`ELSE` 部分给 `$0$`。
    *   如果是统计次数，可以用 `COUNT(CASE WHEN ... THEN 1 ELSE NULL END)` 或者 `SUM(CASE WHEN ... THEN 1 ELSE 0 END)`。后者更常用。
*   **条件判断**：`IF(cond, true_val, false_val)` (MySQL, Hive) 或 `CASE WHEN cond THEN true_val ELSE false_val END` (通用)。

---

## 1.4 三、附：列转行 (简单提及)
![image.png](https://raw.githubusercontent.com/SAMLAY-c/obsidian-photos/university/img/20250620114924793.png)

*   **一句话概括**：跟行转列反过来，把原来横着的一条记录里的多个列信息，拆成竖着的多条记录显示。
*   **场景**：当数据以宽表形式存储，但分析时需要按每个属性单独作为一行进行处理时。
*   **核心技术 (Hive中)**：`LATERAL VIEW EXPLODE(SPLIT(column_to_split, delimiter))`
    *   `SPLIT(string, delimiter)`: 将一个字符串按指定分隔符拆分成一个数组 (array)。
    *   `EXPLODE(array)`: 将数组中的每个元素炸开，变成单独的一行。
    *   `LATERAL VIEW`: Hive特有的语法，用于配合 `EXPLODE` 等UDTF(用户定义表生成函数)，能将UDTF生成的每一行和原始输入行关联起来。

### 1.4.1 例子：腾讯QQ面试题 (表B转表A，即列转行)

*   **原始表B (假设表名叫 `user_games_wide`)**：
    | qq    | games     |
    | :---- | :-------- |
    | 10001 | a_b_c     |
    | 10002 | c_d       |
*   **目标表A (假设表名叫 `user_games_long`)**：
    | qq    | game |
    | :---- | :--- |
    | 10001 | a    |
    | 10001 | b    |
    | 10001 | c    |
    | 10002 | c    |
    | 10002 | d    |

*   **SQL代码实现与解析 (Hive SQL)**：

    *   **步骤1：创建表和插入数据 (Hive SQL 示例)**
        ```sql
        CREATE TABLE IF NOT EXISTS user_games_wide (
            qq STRING,
            games STRING -- 存储用下划线分隔的游戏列表
        );
        INSERT INTO user_games_wide VALUES
        ('10001', 'a_b_c'),
        ('10002', 'c_d');

        -- 顺便创建目标格式的表A，虽然查询时不需要，但对照用
        CREATE TABLE IF NOT EXISTS user_games_long (
            qq STRING,
            game STRING
        );
        INSERT INTO user_games_long VALUES
        ('10001', 'a'),
        ('10001', 'b'),
        ('10001', 'c'),
        ('10002', 'c'),
        ('10002', 'd');
        ```

    *   **步骤2：列转行查询**
        ```sql
        SELECT
            t.qq, -- 原始表中的qq号
            exploded_game_view.single_game -- 炸开后每个游戏项的新列名
        FROM
            user_games_wide t -- t是原始表user_games_wide的别名
        LATERAL VIEW EXPLODE(SPLIT(t.games, '_')) exploded_game_view AS single_game;
        -- 解释:
        -- 1. SPLIT(t.games, '_'): 比如对于第一行，'a_b_c' 被下划线 '_' 分割成数组 ['a', 'b', 'c']。
        -- 2. EXPLODE(['a', 'b', 'c']): 把数组 ['a', 'b', 'c'] 炸开，变成三行，每行分别是 'a', 'b', 'c'。
        -- 3. LATERAL VIEW ... exploded_game_view AS single_game:
        --    - exploded_game_view: 这是为EXPLODE操作产生的临时虚拟表（视图）起的名字。
        --    - AS single_game: 这是给这个虚拟表中炸开来的那一列起的名字。
        --    - LATERAL VIEW 的作用是把原始表的每一行 (比如 qq='10001', games='a_b_c') 与其 games 列炸开后的每一行 ('a', 'b', 'c') 进行连接。
        --      所以对于 qq='10001'，它会产生三条记录：
        --      ('10001', 'a')
        --      ('10001', 'b')
        --      ('10001', 'c')
        ```
    *   **#注意#**：`LATERAL VIEW EXPLODE` 是Hive/Spark SQL等大数据SQL引擎中常用的，标准SQL可能需要用其他更复杂的方式或UDF来实现类似功能。

---

## 1.5 四、专题二：连续N天登录

*   **一句话概括**：找出哪些用户连续登录了（或活跃了）至少N天，比如找出连续签到3天的用户都有谁。
*   **核心公式/思路 (方案一：日期差值法 - 老师主流方案)**：
    1.  **`DISTINCT` (用户, 日期)**：确保每人每天只有一条登录记录。(#去重预处理)
    2.  **`ROW_NUMBER() OVER (PARTITION BY 用户 ORDER BY 日期)`**: 给每个用户的登录日期进行排名（生成序号 `rn`）。(#打序号)
    3.  **`DATE_SUB(日期, rn)` (或 日期 - rn天)**：计算一个“分组日期标记”。如果用户是连续登录的，这个标记日期会是相同的。(#计算日期差，找连续标记)
        *   **原理**：
            假设一个用户连续登录日期是：`D1, D2, D3` (D2=D1+1天, D3=D2+1天)
            对应的序号 `rn` 是：`1, 2, 3`
            计算差值：
            `D1 - 1天`
            `D2 - 2天 = (D1+1天) - 2天 = D1 - 1天`
            `D3 - 3天 = (D1+2天) - 3天 = D1 - 1天`
            看到没？对于连续登录的日期，这个差值是恒定的！
    4.  **`GROUP BY 用户, 分组日期标记`**: 按用户和上一步算出的“分组日期标记”进行分组。
    5.  **`COUNT(*) AS 连续天数`**: 统计每个组内的记录数，这就是该用户在该次连续登录中的天数。
    6.  **`HAVING COUNT(*) >= N`**: 筛选出连续天数达到N天的组。
    7.  **`SELECT DISTINCT 用户`**: 获取最终满足条件的用户名列表 (如果只需要用户列表)。

### 1.5.1 例子：OPPO面试题 (查询连续3天登录的用户姓名)

*   **原始数据 (假设表名 `game_log`)**：包含 `name` (姓名) 和 `date` (登录日期，字符串格式如 '2020-01-01')，可能有重复登录。
*   **目标**：找出连续登录至少3天的用户姓名。

*   **SQL代码实现与解析 (Hive SQL，使用 `WITH AS` CTE)**
    `WITH AS` (Common Table Expression, 公用表表达式) 可以让复杂的SQL分步骤写，更清晰易读，就像搭积木一样，每一步的结果作为下一步的输入。

    *   **步骤1：创建表和插入数据 (模拟老师的数据)**
        ```sql
        CREATE TABLE IF NOT EXISTS game_log (
            name STRING,
            `date` STRING -- date是关键字，用反引号包起来
        );
        -- 假设插入了类似这样的数据，可能有重复：
        -- ('张三', '2020-01-01'), ('张三', '2020-01-01'), ('张三', '2020-01-02'), 
        -- ('张三', '2020-01-03'), ('张三', '2020-01-05'), ('李四', '2020-01-01'), ...
        -- 老师的数据:
        INSERT INTO game_log VALUES
        ('张三', '2020-01-01'), ('张三', '2020-01-02'), ('张三', '2020-01-02'), ('张三', '2020-01-03'), ('张三', '2020-01-04'),
        ('李四', '2020-01-01'), ('李四', '2020-01-02'), ('李四', '2020-01-04'), ('李四', '2020-01-05'), ('李四', '2020-01-06'),
        ('王五', '2020-01-01'), ('王五', '2020-01-03'); 
        -- 老师的例子中，张三在01-04没有登录，而是01-01, 01-02, 01-03连续。我们按视频里的数据来。
        -- 视频中给出的查询结果是张三连续登录了。说明他的数据是01,02,03,04。
        -- 我们用老师PPT里的数据，最后结果是张三和李四都符合连续3天。
        -- 更改一下数据以匹配老师的演示，老师的数据是：
        -- 张三: 01,02,03,04 (所以01-03, 02-04都算连续3天)
        -- 李四: 01,02,04,05,06 (所以04-06算连续3天)
        -- 王五: 01,03 (不连续)
        -- 原始表需要先清洗，老师的表叫game，我们还叫game_log
        TRUNCATE TABLE game_log; -- 先清空，如果之前有数据
        INSERT INTO game_log VALUES
        ('张三', '2020-01-01'), ('张三', '2020-01-02'), ('张三', '2020-01-02'), ('张三', '2020-01-03'),('张三', '2020-01-04'), -- 张三连续4天
        ('李四', '2020-01-01'), ('李四', '2020-01-02'), ('李四', '2020-01-04'),('李四', '2020-01-05'),('李四', '2020-01-06'), -- 李四在04,05,06连续3天
        ('王五', '2020-01-01'), ('王五', '2020-01-03');
        ```

    *   **步骤2：使用 `WITH AS` 分步查询**
        ```sql
        WITH 
        -- 第1步：对用户的登录日期去重，确保每人每天只有一条记录
        t1_distinct_log AS (
            SELECT DISTINCT
                name,
                `date` -- date是关键字，用反引号
            FROM game_log
        ),

        -- 第2步：为每个用户按登录日期排序并打上序号(rn)
        -- ROW_NUMBER() OVER(PARTITION BY 分组列 ORDER BY 排序列) 是窗口函数
        -- PARTITION BY name: 在每个name分组内部分别进行编号
        -- ORDER BY `date`: 在每个name分组内部，再按照date升序排列，然后编号
        t2_ranked_log AS (
            SELECT
                name,
                `date`,
                ROW_NUMBER() OVER (PARTITION BY name ORDER BY `date`) AS rn
            FROM t1_distinct_log
        ),

        -- 第3步：计算日期差，得到分组标记 (grp_date)
        -- DATE_SUB(start_date, num_days): 返回start_date减去num_days天后的日期
        -- 比如 DATE_SUB('2020-01-03', 2) 结果是 '2020-01-01'
        t3_group_mark AS (
            SELECT
                name,
                `date`,
                rn,
                DATE_SUB(`date`, rn) AS grp_date -- 核心：日期减序号天数
            FROM t2_ranked_log
        ),

        -- 第4步：按用户和分组标记(grp_date)分组，统计每个组内的天数(即连续天数)
        t4_consecutive_count AS (
            SELECT
                name,
                grp_date, -- 虽然SELECT出来，但主要用于GROUP BY
                COUNT(*) AS consecutive_days -- 统计每个(name, grp_date)组合有多少条记录
            FROM t3_group_mark
            GROUP BY name, grp_date
        )

        -- 第5步：从上一步的结果中筛选出连续天数 >= 3 的用户，并去重得到最终名单
        SELECT DISTINCT
            name
        FROM t4_consecutive_count
        WHERE consecutive_days >= 3; -- 筛选条件
        ```
        **#窗口函数 ROW_NUMBER() 详解#**
        `ROW_NUMBER() OVER (PARTITION BY col1 ORDER BY col2)`
        *   `PARTITION BY col1`：将数据按照 `col1` 列的值分成若干个“窗口”或“分区”。在每个分区内独立进行编号。如果省略，整个结果集视为一个分区。
        *   `ORDER BY col2`：在每个分区内，根据 `col2` 列的值进行排序。`ROW_NUMBER()` 会根据这个顺序从 `$1$` 开始分配连续的整数编号。
        *   **例子**：对于张三的记录，`PARTITION BY name` 会把所有张三的记录放在一个组里，然后 `ORDER BY date` 会把张三的登录日期排序，再从 `$1$` 开始编号。李四同理。

        **#DATE_SUB(date, days) 函数#**
        *   这是Hive (以及MySQL) 中的日期函数，用于从一个日期减去指定的天数。
        *   `date`: 可以是日期字符串（如 '2020-01-01'）或日期类型的列。
        *   `days`: 要减去的天数，是一个整数。
        *   例如：`DATE_SUB('2020-01-03', 2)` 结果是 `'2020-01-01'`。
        *   在其他数据库中，日期运算函数可能不同：
            *   PostgreSQL: `date_column - INTERVAL '1 day' * rn`
            *   SQL Server: `DATEADD(day, -rn, date_column)`
            *   Oracle: `date_column - rn` (如果rn是数字，Oracle可以直接日期加减数字表示天数)

    *   **结果**：根据上面插入的数据和逻辑，最终会输出 '张三' 和 '李四'。

    *   **#老师提到的 `WHERE` 和 `HAVING` 的替换#**
        老师说 `WHERE count >= N` 可以换成 `HAVING count >= N`。这里有个细微差别：
        *   如果 `count` 是在 `SELECT` 子句中通过聚合函数 `COUNT(*)` 生成的别名，并且你想在同一个查询级别中基于这个别名进行过滤，那么标准的做法是用 `HAVING` 子句，因为 `HAVING` 是在 `GROUP BY` 和聚合之后执行的。
        *   老师的 `WITH AS` 写法中，`consecutive_days` 是在 `t4_consecutive_count` 这个CTE中计算出来的。在最后一个 `SELECT` 语句中，`t4_consecutive_count` 相当于一个表，`consecutive_days` 是这个表里已有的列，所以用 `WHERE consecutive_days >= 3` 是完全正确的，这是对 `t4` 的行级过滤。
        *   如果把 `t4` 和最后的 `SELECT` 合并成一步，那么就需要用 `HAVING`：
            ```sql
            -- 合并t4和最后一步的写法
            SELECT name -- , COUNT(*) AS consecutive_days (如果需要显示连续天数)
            FROM t3_group_mark
            GROUP BY name, grp_date
            HAVING COUNT(*) >= 3;
            -- 然后如果只需要name，还需要再套一层 SELECT DISTINCT name FROM (...)
            ```
            所以老师的 `WITH AS` 写法更清晰。

### 1.5.2 方案二：LEAD/LAG 窗口函数法 (老师预告下次讲)

*   **一句话概括思路**：对于用户的每次登录，看它后面几次的登录是否是紧挨着的（比如用 `LEAD` 函数找到下一次、下下次登录日期，看是否分别是当前日期+1天、+2天）。
*   这个方案老师说下次详细讲，这里就不展开了，但知道有这么个思路。

---

## 1.6 五、后续专题预告 (老师提及的)

老师提到后面还会讲这些专题，并且也都会总结出“公式”：

1.  **N日留存率**：比如次日留存、7日留存等。也有固定套路。
2.  **分组内TopN**：比如找出每个部门工资最高的前3名。会用到窗口函数如 `ROW_NUMBER()`, `RANK()`, `DENSE_RANK()`。
3.  **窗口函数专题**：深入讲解各种窗口函数的用法。
4.  **带条件的聚合统计**：类似行转列中的 `SUM(IF(...))`，但可能更复杂。

今天的核心是把 **行转列** 和 **连续N天登录 (方案一)** 的套路理解透彻，多练习几遍，就能变成自己的东西！