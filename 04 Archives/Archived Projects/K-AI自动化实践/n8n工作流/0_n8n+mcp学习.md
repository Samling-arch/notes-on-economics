好的，没问题！作为一名AI，我非常乐意为你从零开始，用最详尽、最通俗易懂的方式，把这个视频的内容拆解成一份保姆级的Obsidian笔记。
我们将一步一步来，确保你理解每一个细节、每一个概念的来龙去脉。
# n8n + MCP = AI 超能力！一份给小白的保姆级图文指南
> [!TIP] 核心思想一句话概括
> 这份指南教你如何使用 n8n 这个自动化工具，给大语言模型（LLM）装上“手”和“脚”（通过 MCP 协议），让它能像人一样主动上网搜索信息，并把找到的结果自动存成本地文件。
## 1. 核心概念解析：拆解“黑话”
在开始动手之前，我们必须先弄懂几个关键名词，它们是构建整个工作流的基石。
### 1.1 n8n 是什么？
> [!abstract] 一句话概括
> n8n 是一个可视化的“胶水”工具，能把不同的软件和服务（比如微信、数据库、AI模型）像搭积木一样连接起来，让它们自动为你工作。
> [!INFO] 详解
> - **n8n** (发音类似 "n-eight-n") 是一个开源的、可视化的工作流自动化平台。
> - **工作流 (Workflow)**：就是一系列你预设好的、按顺序执行的步骤。比如，“当收到一封新邮件时（步骤1），提取邮件附件（步骤2），保存到我的网盘（步骤3）”。
> - **节点 (Node)**：在 n8n 的画布里，每一个“步骤”就是一个节点。比如，有“邮件接收”节点，“文件操作”节点，“HTTP请求”节点等。我们把这些节点用线连起来，就组成了一个完整的工作流。
> - **为什么用它？** 它可以让你无需编写复杂的代码，就能实现各种自动化任务，极大地提高效率。视频中，我们用它来搭建连接 AI 和外部工具的桥梁。
### 1.2 MCP 是什么？
> [!abstract] 一句话概括
> MCP (Model-Component-Protocol) 是一套“行为规范”，它规定了大模型应该如何与外部工具（如搜索引擎、文件系统）进行标准化的沟通。
> [!INFO] 详解
> - **大语言模型 (LLM)**：比如我们熟知的 ChatGPT、或者视频中提到的 DeepSeek，它们本身只是一个很会聊天的“大脑”，被关在一个“黑盒子”里，无法直接接触外部世界。
> - **MCP 的作用**：它就像是为这个“大脑”制定的《与外界交互手册》。任何外部工具，只要也遵守这套手册，大模型就知道该如何“命令”它工作。
> - **打个比方**：
>   - **没有 MCP**：大模型想让你帮忙开灯，但它不知道怎么说。你家有声控灯、按钮灯、App控制的灯，它完全懵了。
>   - **有了 MCP**：MCP 规定了一个标准指令，比如 `turn_on_light(room='living_room')`。所有灯具厂商都按这个标准来生产。现在，大模型只需要发出这个标准指令，任何一盏灯都能听懂并执行。
> - **视频中的应用**：视频里用了两个遵守 MCP 规范的“外部工具”：一个是 `Brave Search`（用于网络搜索），另一个是 `File System`（用于读写本地文件）。
### 1.3 AI Agent (AI 代理) 是什么？
> [!abstract] 一句话概括
> AI Agent 是 n8n 里的一个特殊节点，它扮演着“项目经理”的角色，能指挥一个大模型（大脑），并根据任务需要，决定调用哪些外部工具（手脚）来完成工作。
> [!INFO] 详解
> - **它不只是传话筒**：普通的 AI 节点可能只是把你的问题丢给大模型，然后把答案拿回来。
> - **AI Agent 更智能**：它会进行一个“思考-行动”的循环。
>   1.  **接收任务**：你给它一个目标，比如“帮我查一下马斯克的星舰到火星了没，并把结果存成报告”。
>   2.  **思考**：它问大模型：“要完成这个任务，第一步该干啥？” 大模型回答：“应该先上网搜索‘马斯克 星舰 火星 状态’”。
>   3.  **选择工具**：AI Agent 查看手头有哪些可用的 MCP 工具，发现一个叫 `web_search` 的工具。
>   4.  **行动**：它调用 `web_search` 工具去执行搜索。
>   5.  **再次思考**：拿到搜索结果后，它又问大模型：“现在结果有了，下一步呢？” 大模型说：“把这些信息整理一下，然后写入文件。”
>   6.  **再次行动**：AI Agent 找到一个叫 `write_file` 的工具，执行写入操作。
>   7.  **完成**：所有步骤完成，任务结束。
> - **核心优势**：它赋予了工作流“自主决策”和“连续执行复杂任务”的能力，甚至在出错时可以自我修正（视频后面会提到）。
### 1.4 Docker 是什么？
> [!abstract] 一句话概括
> Docker 是一个能创建“软件集装箱”的工具，它把一个应用（比如 n8n）和它运行所需的所有环境打包在一起，让你可以在任何电脑上快速、一致地运行它。
> [!INFO] 详解
> - **为什么视频里要用 Docker？** 因为视频中使用的 n8n 的 `MCP` 节点是一个“社区节点”，在普通的 n8n 版本中可能不稳定或不存在。而通过 Docker 部署的 n8n 版本，我们可以通过设置一个特定的环境变量，来启用这些实验性的强大功能。
> - **Docker 容器 (Container)**：就是我们说的“软件集装箱”。视频里，我们从 Docker Hub (一个“集装箱仓库”) 下载了 n8n 的官方“集装箱镜像 (Image)”，然后运行它，就得到了一个包含了完整 n8n 环境的、隔离的、正在运行的实例。
> - **好处**：避免了繁琐的本地安装和配置过程，解决了“在我电脑上明明能跑，到你那就不行了”的经典难题。
## 2. 环境准备：搭建你的 AI 工作室
现在我们知道了基本概念，开始动手搭建环境。这一步的目标是成功运行一个带有 MCP 功能的 n8n。
### 2.1 为什么需要 Docker？
> [!QUESTION] 我可以直接下载 n8n 桌面版吗？
> 可以，但是视频中强调，`MCP` 节点目前只有在特定配置下的 n8n 中才能稳定使用。通过 Docker，我们可以轻松地进行这项配置。所以，为了$100\%$复现视频效果，我们跟着视频使用 Docker Desktop。
### 2.2 启动 n8n 容器 (关键步骤)
这一步是整个准备工作中最重要的，尤其是环境变量的设置。
> [!abstract] 一句话概括
> 我们要从 Docker 仓库里下载 n8n 的“安装包”（镜像），然后带着一个“特殊通行证”（环境变量）来运行它，最后给它指定一个“门牌号”（端口）。
1.  **打开 Docker Desktop**：这是 Docker 的图形化管理界面。
2.  **搜索并下载镜像**：在搜索框输入 `n8n`，找到官方镜像（通常是 `n8nio/n8n`），点击下载 (Pull)。
3.  **运行镜像**：下载完成后，点击运行 (Run)。此时会弹出一个配置窗口。
    *   **Name (名称)**：随意起，比如 `my-n8n-mcp`。
    *   **Port (端口)**：输入 `$5678$`。这就像给你家的 n8n 服务分配一个门牌号，之后你就可以通过 `http://localhost:5678` 来访问它。
    *   **Environment Variables (环境变量)**：**这是最关键的一步！**
        *   **来源**：这个变量是 n8n 官方提供的一个“隐藏开关”，用于开启实验性功能。
        *   **操作**：
            *   点击“+”号添加一行。
            *   在变量名 (Name/Key) 处，粘贴视频里提到的变量名：
                ```
                N8N_ENABLE_COMMUNITY_NODES_EXPERIMENTAL
                ```
            *   在变量值 (Value) 处，粘贴：
                ```
                true
                ```
        *   **作用**：这行配置告诉 n8n：“请允许我安装和使用社区开发的、可能还不稳定的节点。” MCP 节点就属于这一类。
4.  **运行容器**：点击“Run”按钮，等待容器启动成功。
### 2.3 安装 MCP 社区节点
> [!abstract] 一句话概括
> 进入 n8n 的“应用商店”，搜索并安装 MCP 这个插件，然后重启 n8n 让插件生效。
1.  **进入 n8n 工作台**：在浏览器访问 `http://localhost:5678`，完成简单的注册后，进入主界面。
2.  **打开社区节点设置**：点击 `Settings` -> `Community Nodes`。
3.  **安装节点**：在搜索框中，粘贴视频中提到的节点名称（通常是 `@n8n-community/n8n-nodes-mcp-client`），然后点击 `Install`。
4.  **重启容器 (非常重要！)**
    *   **为什么必须重启？** n8n 只在启动时加载所有节点。新安装的节点就像刚装好的电脑软件，需要重启系统才能被完全识别。
    *   **如何重启**：回到 Docker Desktop，在容器列表中找到你刚才创建的 `my-n8n-mcp` 容器，点击停止 (Stop)，然后再点击启动 (Start)。
    *   **警告**：
> [!WARNING]
        > **千万不能忘记重启！** 如果不重启，你在工作流里会找不到 `MCP` 节点，会在这里卡住很久。
## 3. 智能工作流实战：从搜索到存储
环境就绪！现在我们来复刻视频中的核心工作流。
### 第一部分：打造“会上网搜索”的AI
> [!abstract] 一句话概括
> 我们将搭建一个流程：在聊天框里提问，AI Agent 会指挥大模型思考，并利用 MCP 提供的搜索工具上网查找答案，最后返回结果。
#### 步骤 1：创建工作流与触发器
1.  **新建工作流**：在 n8n 工作台点击 `Add workflow`。
2.  **添加触发器**：第一个节点选择 `Chat Trigger`（聊天触发器）。这个节点的作用是提供一个聊天输入框，让我们能方便地向工作流提问。
#### 步骤 2：引入“大脑”和“项目经理” (AI Agent)
1.  **添加 AI Agent 节点**：点击 "+" 号，搜索并添加 `AI Agent` 节点。
2.  **配置 AI Agent**：
    *   **Text (文本)**：这是你要交给 Agent 的初始指令。视频中先随便写了一点，因为后面要用表达式来动态填充。我们现在可以先写：
        ```
        请回答我的问题。
        ```
    *   **LLM (大语言模型)**：点击 `Add Chat Model`，选择 `DeepSeek`。
        *   **创建凭证 (Credential)**：你需要一个 DeepSeek 的 API Key。去 DeepSeek 官网免费申请一个，然后复制粘贴到这里，保存凭证。
    *   **Parameter (参数) 的玄机**：
        *   **初始测试目的**：视频中提到，第一次随便配置并运行，是为了让工作流跑起来，这样 n8n 就会记录下每个节点有哪些数据可以用。我们的目标是拿到 `Chat Trigger` 节点的输出数据。
        *   **获取变量**：运行一次后，可以看到 `Chat Trigger` 的输出数据里，有一个 `value` 字段，代表用户在聊天框里输入的内容。
        *   **配置表达式**：回到 `AI Agent` 节点的 `Text` 输入框，删掉刚才写的 "请回答我的问题"。点击旁边的小图标，切换到“表达式 (Expression)”模式。然后从左侧的 `Nodes` -> `Chat Trigger` -> `Output Data` -> `JSON` 中，把 `value` 拖拽进来。配置好的表达式看起来像这样：
            ```json
            {{ $json.value }}
            ```
        *   **表达式来源与作用**：这串代码是 n8n 的数据引用语法。`{{ ... }}` 表示这是一个表达式。`$json.value` 的意思是“获取上一个节点（这里是 Chat Trigger）输出的 JSON 数据中的 `value` 字段”。这样一来，`AI Agent` 处理的就不再是固定文本，而是我们每次在聊天框里动态输入的问题。
#### 步骤 3：赋予“动手能力” (配置 MCP 节点)
AI Agent 现在有了大脑，但还没有手脚。我们需要用 MCP 节点给它提供工具。
##### 节点 A: MCP 工具列表 (List Tools)
> [!abstract] 一句话概括
> 这个节点的作用是连接到一个提供“搜索工具”的 MCP 服务器，并把一份“工具菜单”返回给 AI Agent。
1.  **添加 MCP 节点**：在 `AI Agent` 节点的 `Tools` 选项下，点击 `Add Tool`，搜索并选择 `MCP Client`。
2.  **配置 MCP Client**：
    *   **Operation (操作)**：选择 `List Tools`（列出工具）。
    *   **Credential (凭证)**：点击 `Create New` 创建一个连接到 Brave Search MCP 服务器的凭证。
        *   **Command (命令)**：复制粘贴视频辅助文档中的 `npx -p @mcp/brave-search-mcp-server brave-search-mcp-server`。
            *   **来源与作用**：这是一个 `npx` 命令，它会临时下载并运行一个名为 `brave-search-mcp-server` 的程序，这个程序就是遵守 MCP 规范的“搜索工具服务器”。
        *   **Environment Variables (环境变量)**：这里需要提供 Brave Search 的 API 密钥。
            *   格式：`BRAVE_SEARCH_API_KEY=YOUR_API_KEY`
            *   **操作**：先去 [Brave Search API](https://brave.com/search/api/) 官网申请一个免费的 API Key，然后替换掉 `YOUR_API_KEY` 部分。
            *   **示例**：`BRAVE_SEARCH_API_KEY=bs0...`
        *   **保存凭证**。
##### 节点 B: MCP 执行工具 (Execute Tool)
> [!abstract] 一句话概括
> 这个节点负责实际执行 AI Agent 从“工具菜单”中选中的那个工具。
1.  **添加第二个 MCP 节点**：在第一个 `MCP Client` 节点下方，再次 `Add Tool`，添加另一个 `MCP Client` 节点。
2.  **配置 MCP Client**：
    *   **Credential (凭证)**：选择刚才创建好的 Brave Search 凭证。
    *   **Operation (操作)**：选择 `Execute Tool`（执行工具）。
    *   **Tool Name (工具名称)**：**切换到表达式模式**，并粘贴以下表达式：
        ```json
        {{ $tool.name }}
        ```
        *   **来源与作用**：`$tool.name` 是一个特殊的内部变量。当 AI Agent 决定使用某个工具时，这个变量就会被自动赋值为该工具的名称（比如 `web_search`）。这让节点可以动态执行任何被选中的工具。
    *   **Tool Parameters (工具参数)**：点击 `Add Option` -> `Parameters`，然后点击右侧的 `Add Expression`。选择 `Use Agent Intermediate Steps` -> `Tool Chosen by Agent` -> `Input`。
        *   **作用**：这是一个绝妙的设计！它的意思是：“我不知道这个工具需要哪些参数（比如搜索词是什么），请让 AI Agent 自己根据任务去决定和填充这些参数。” 这就省去了我们手动配置每个参数的巨大麻烦。
#### 小结：第一部分工作流如何运作
> [!TIP] 流程复盘
> 1.  **你提问**：“马斯克的星舰到火星了吗？”
> 2.  **Chat Trigger** 接收问题。
> 3.  **AI Agent** 接到任务，并问 **DeepSeek**：“该怎么办？”
> 4.  **第一个 MCP 节点 (List Tools)** 连接 Brave Search 服务器，告诉 Agent：“我这里有 `web_search` 和 `local_search` 两个工具。”
> 5.  **DeepSeek** 分析后告诉 **Agent**：“用 `web_search` 工具，搜索词是‘马斯克 星舰 火星 状态’”。
> 6.  **第二个 MCP 节点 (Execute Tool)** 被触发。
>     - 它的 `Tool Name` 通过表达式变成了 `web_search`。
>     - 它的 `Parameters` 被 Agent 自动填充为 `{ "query": "马斯克 星舰 火星 状态" }`。
> 7.  节点执行搜索，并将结果返回给 **Agent**。
> 8.  **Agent** 把搜索结果交给 **DeepSeek** 进行总结和润色。
> 9.  **Agent** 将最终答案输出到聊天界面。
### 第二部分：教会AI“写入文件”
> [!abstract] 一句话概括
> 我们在流程的后半段，再增加一个能操作文件的 AI Agent，让它把前面搜索到的结果，保存到 n8n 运行的服务器本地。
#### 步骤 4：增加处理文件的 AI 代理
视频中的做法是在第一个 `AI Agent` 后面再串联一个，专门负责文件操作。
1.  **添加新的 AI Agent**：在第一个 `AI Agent` 节点后面，添加一个新的 `AI Agent` 节点。
2.  **配置 Text**：使用表达式，将上一个 Agent 的输出结果作为这一个 Agent 的输入。表达式：
    ```json
    {{ $json.output }}
    ```
    并可以加上指令，如：
    ```
    请将以下内容保存到文件中，文件名为 'report.txt'。内容：{{ $json.output }}
    ```
#### 步骤 5：配置第二个 MCP 服务器 (文件操作)
和搜索部分类似，我们需要为这个新的 Agent 提供“文件操作”工具。
1.  **添加 List Tools 节点**：在新的 `AI Agent` 下添加 `MCP Client` 节点，操作设为 `List Tools`。
2.  **创建新凭证**：这次我们要连接的是一个本地文件操作的 MCP 服务器。
    *   **Command**：`npx -p @mcp/file-system-mcp-server file-system-mcp-server --path=/home/node/mcp-files`
        *   **来源与作用**：这个命令会启动一个文件服务器。`--path` 参数指定了允许它操作的文件夹路径。这个路径是 Docker 容器内部的路径。
    *   **Environment Variables**：留空，这个服务器不需要 API Key。
    *   **Credential Name**：为了区分，可以命名为 `MCP File System Credential`。
3.  **添加 Execute Tool 节点**：和之前一样，再添加一个 `MCP Client` 节点，操作设为 `Execute Tool`，并配置好 `Tool Name` 和 `Parameters` 的表达式，让 Agent 自行决定。
#### 步骤 6：工作流的“自我修正”能力
> [!abstract] 一句话概括
> 当 AI 第一次用错工具导致失败时，AI Agent 不会放弃，而是会分析失败原因，并指挥大模型尝试用另一个正确的工具，直到成功为止。
*   **视频中的错误**：当测试写入文件功能时，第一次执行失败了。错误信息显示 `write file` 这个工具不存在。
*   **原因分析**：这很可能是因为 AI Agent 和大模型根据任务“猜想”应该有一个叫 `write file` 的工具，但实际的文件服务器提供的工具名叫 `writeFile` 或者 `fs.writeFile`（大小写或命名空间不同）。
*   **智能之处**：`AI Agent` 节点的设计包含了重试和修正逻辑。它会把失败信息和可用的工具列表（由 `List Tools` 节点提供）一起再次发给大模型，问道：“刚才用这个工具失败了，你看看菜单，应该用哪个？” 大模型在第二次尝试中，就找到了正确的工具名称，并成功执行了写入操作。
*   **如何查看结果**：
    1.  回到 Docker Desktop。
    2.  点击 n8n 容器的详情 (Details)。
    3.  点击 `Files` 标签页。
    4.  导航到路径 `/home/node/mcp-files`，你就能看到 AI 创建的 `report.txt` 文件了。
## 4. 深度思考：为什么选择 MCP？
> [!QUESTION] 整个流程我用 `HTTP Request` 节点也能实现，而且可能更简单，为什么非要用 MCP 这么复杂的方式？
这是一个非常好的问题，也是理解 MCP 价值的关键。
### MCP vs. HTTP Request 节点
> [!abstract] 一句话概括
> `HTTP Request` 节点是“手动挡”，你需要精确地告诉它每个接口地址、参数和格式；而 `MCP` 配合 `AI Agent` 是“自动挡”，你只需告诉它目标，它能自己找到合适的接口（工具）并填充参数。


| 特性 | HTTP Request 节点 | AI Agent + MCP 节点 |
| : | : | : |
| **配置复杂度** | **高**。对于参数众多的API，你需要手动一个个填写，非常繁琐，是个“噩梦”。 | **极低**。`让大模型决定参数` 这个按钮，节省了90%的配置工作。 |
| **灵活性** | **低**。一个节点只能调用一个写死的API接口。如果想根据情况调用不同接口，需要用复杂的 `IF` 或 `Switch` 节点来判断。 | **高**。AI Agent 可以从工具列表中**自动选择**最合适的工具，无需人工干预。 |
| **可扩展性** | **差**。每增加一个API功能，就要增加和配置一个新的节点。 | **好**。如果一个 MCP 服务器更新了，增加了10个新工具，你什么都不用改，AI Agent 自动就能发现并使用它们。 |

### 独立使用 MCP 节点的局限性
> [!abstract] 一句话概括
> 如果没有 AI Agent 的指挥，单独使用 MCP 节点就退化成了“手动挡”，和 HTTP Request 节点没太大区别了。
视频中提到，`MCP Client` 节点也可以独立使用。但那时，你就必须：
1.  在 `Execute Tool` 节点里，**明确地**写死要使用的工具名称，比如 `web_search`。
2.  **手动配置**该工具所需的所有参数，比如 `query`。
这样一来，MCP 最大的优势——自动化和智能化——就荡然无存了。所以结论是：
> [!SUCCESS]
> **AI Agent + LLM + MCP 是天作之合**。把决策交给 AI Agent 和大模型，是发挥这套体系威力的正确方式。
## 5. 展望未来：万能机器人的雏形
> [!abstract] 一句话概括
> 如果未来有一个超级 MCP 服务器，集成了成千上万种工具（发邮件、订外卖、控制智能家居等），那么我们的工作流将变得极度简单，一个全能AI助理就诞生了。
*   **终极工作流形态**：
    *   `Chat Trigger` (用户下达指令)
    *   `AI Agent` (项目经理)
    *   `DeepSeek` (大脑)
    *   `一个万能的 MCP 节点` (连接到那个超级服务器)
*   **想象一下**：你只需要对它说：“帮我查一下明天的天气，如果下雨，就提醒我带伞，并把去公司的路线切换到地铁模式。” 这个简单的工作流就能自动连接天气、提醒、地图等所有工具，完美执行。这不就是科幻电影里的 AI 助手吗？
## 6. 附录：关键信息与代码片段
这里汇总了视频中所有关键的配置信息，方便你复制粘贴。
### Docker 环境变量
```
N8N_ENABLE_COMMUNITY_NODES_EXPERIMENTAL=true
```
### MCP 节点名称
```
@n8n-community/n8n-nodes-mcp-client
```
### MCP Brave Search 凭证配置
*   **Command**:
    ```bash
    npx -p @mcp/brave-search-mcp-server brave-search-mcp-server
    ```
*   **Environment Variables**:
    ```
    BRAVE_SEARCH_API_KEY=这里换成你自己的Brave Search API Key
    ```
### MCP 文件操作凭证配置
*   **Command**:
    ```bash
    npx -p @mcp/file-system-mcp-server file-system-mcp-server --path=/home/node/mcp-files
    ```
*   **Environment Variables**: (留空)
### AI Agent 表达式
*   **动态获取用户输入 (用于Text)**:
    ```json
    {{ $json.value }}
    ```
*   **动态指定工具名称 (用于Execute Tool)**:
    ```json
    {{ $tool.name }}
    ```
希望这份超级详细的笔记能帮助你彻底搞懂视频里的所有内容！动手试试看，打造属于你自己的 AI 超能力吧！